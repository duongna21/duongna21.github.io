---
title: "MFinBERT: Multilingual Pretrained Language Model For Financial Domain"
category: articles
permalink: "/articles/MFINBERT/"
venue: "International Conference on Knowledge and Systems Engineering (KSE)"
date: 01-09-2022
link: 
---
[comment]: <> (<a href="https://arxiv.org/abs/2002.07367">Arxiv</a>.)
<b>Duong Nguyen</b>\*, Nam Cao\*, Son Nguyen\*, Son Ta, Cuong Dinh

Abstract: There has been an increasing demand for good semantic representations of text in the financial sector when solving natural language processing tasks in Fintech. Previous work has shown that widely used modern language models trained in the general domain often perform poorly in this particular domain. There have been attempts to overcome this limitation by introducing domain-specific language models learned from financial text. However, these approaches suffer from the lack of in-domain data, which is further exacerbated for languages other than English. These problems motivate us to develop a simple and efficient pipeline to extract large amounts of financial text from large-scale multilingual corpora such as OSCAR and C4. We conduct extensive experiments with various downstream tasks in three different languages to demonstrate the effectiveness of our approach across a wide range of standard benchmarks.
